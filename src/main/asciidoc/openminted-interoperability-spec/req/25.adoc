== Incorporation of multiple resources in parallel

[%hardbreaks]
[small]#*_Concreteness:_* __abstract__#
[small]#*_Strength:_*     __recommended__#
[small]#*_Category:_*     __WG4__#
[small]#*_Status:_*       __deprecated__#

IMPORTANT: This requirement has been deprecated per discussion in WG4. If multiple resources of a type need to be added to a workflow, simply add the same component multiple times, once configured for each resource in question. Engineering components in general such that they support using multiple resources will impose an unnecessary complexity on them and was considered over-engineering.

Whenever possible, components should allow to incorporate multiple resources in parallel, e.g. looking up a word from multiple sources or using multiple classification models in parallel. Examples:

* Stanford CoreNLP named entity recognizer can load multiple NER models in parallel
* a Gazetteer should be able to access not only a single knowledge resources, but be able to access e.g. multiple SparQL endpoints

Components may choose or have to disambiguate results if there are multiple hits, e.g. using a relevance or confidence score, in particular if the annotation scheme being used does not allow for multiple categories to be assigned to a single element (e.g. a Named Entity) or does not allow multiple elements to exist at the same location.

Another alternative would be to add the same component multiple times to a workflow, each time using a different resources - this would require that at least temporarily multiple categories/annotation elements would be allowed. A subsequent component could be used to select the most relevant one(s).

Caveat: Having relevance/confidence scores from different sources bears a great risk of the scores being on different scales and not comparable.

NOTE: parallel access to resources could be externalized into a resource adapter, such that the component itself would not have to deal explicitly with handling multiple adapters in parallel. 

Source: WG 2 Scenario 3 — The relation between documents and knowledge bases through keywords

.See also
* <<REQ-19>>

// Below is an example of how a compliance evaluation table could look. This is presently optional
// and may be moved to a more structured/principled format later maintained in separate files.
[cols="2,1,1,4,1"]
|====
|Product|Version|Compliant|Justification|Status

| Alvis
| 0.5rc
| No
| Not supported
| Draft

| ARGO
| 0.5
| No
| It is possible to model the alternative suggestion using Argo (i.e. using multiple instances of the same component but applying different resources to each one) however there is no subsequent component to determine the most relevant output.  Not sure how this would be implemented at a framework level; seems very use-case specific.
| Draft

| DKPro Core
| 1.8.0
| No
| The most prevasively used mechanism to load models in DKPro Core is the ResourceObjectProvider controlled through the parameters *PARAM_MODEL_LOCATION*, *PARAM_LANGAUGE*, and *PARAM_VARIANT*. This is presently set up in a way that only a single value is permitted for each of these parameters. Hence, e.g. the CoreNlpNamedEntityRecognizer would have to be added multiple times to a pipeline in order to be used with multiple models. The preference resolution mechanism that is normally part of the CoreNLP NER component would have to be modelled as a separate pipeline component (which is currently not offered by DKPro Core). In a few cases, components require multiple models (e.g. OpenNlpSegmenter) in which case we currently use multiple parameters, e.g. *PARAM_TOKENIZATION_MODEL_LOCATION* and *PARAM_SEGMENTATION_MODEL_LOCATION*. A few older components not using the ResourceObjectProvider may support multiple resources to be loaded, e.g. the StopWordRemover component.
| Draft

| GATE
| 8.2
| Unknown
| you could write a GATE component in this way, but it isn't supported directly by the framework and I know of none that do this
| Draft

| ILSP
| 1.2.1
| No
| Not supported in a generic way.
| Draft
|====
